# multi-arm-bandits
Demonstration of following policies for multi-arm bandits problem.
* Exploration only policy
* Exploitation only policy
* e-first policy
* e-greedy policy

_e-greedy_ policy works best so far.
